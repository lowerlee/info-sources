{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# MBFC Enrichment Notebook\n\nThis notebook enriches information sources with Media Bias Fact Check (MBFC) data by scraping bias, factual reporting, and credibility ratings.\n\n## Purpose\nAutomatically fetch MBFC bias, factual, and credibility ratings for sources in the Google Sheet and update the sheet with this information.\n\n## Requirements\n- **Credentials**: `credentials.json` file in the root directory (Google service account)\n- **Dependencies**: beautifulsoup4, requests, google-api-python-client\n- **Sheet Columns**: The sheet must have `mbfc_bias`, `mbfc_factual`, and `mbfc_credibility_rating` columns\n\n## How it works\n1. Connects to Google Sheets and loads source data\n2. For each source without MBFC data:\n   - Searches for the source on mediabiasfactcheck.com\n   - Extracts bias rating, factual reporting rating, and credibility rating\n   - Updates the Google Sheet with the findings\n3. Applies rate limiting to avoid overwhelming MBFC servers\n\n## Columns populated:\n- `mbfc_bias`: Political bias rating (e.g., Left, Center, Right)\n- `mbfc_factual`: Factual reporting rating (e.g., High, Mixed, Low)\n- `mbfc_credibility_rating`: Overall credibility rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import re\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SERVICE_ACCOUNT_FILE = \"credentials.json\"\n",
    "SPREADSHEET_ID = \"1NywRL9IBR69R0eSrOE9T6mVUbfJHwaALL0vp2K0TLbY\"\n",
    "SHEET_RANGE = \"main!A:H\"\n",
    "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "\n",
    "# MBFC Configuration\n",
    "MBFC_BASE_URL = \"https://mediabiasfactcheck.com/\"\n",
    "DELAY_BETWEEN_REQUESTS = 2.0  # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(url: str) -> str:\n    \"\"\"\n    Extract domain name from URL and remove www prefix.\n    \n    Args:\n        url: Full URL string\n        \n    Returns:\n        Domain name without www prefix\n    \"\"\"\n    try:\n        parsed = urlparse(url)\n        domain = parsed.netloc or parsed.path\n        # Remove www prefix\n        if domain.startswith('www.'):\n            domain = domain[4:]\n        return domain\n    except Exception:\n        return \"\"\n\n\ndef search_mbfc(source_name: str, source_url: str) -> Optional[str]:\n    \"\"\"\n    Search for source on MBFC by trying different URL patterns.\n    \n    Args:\n        source_name: Name of the source\n        source_url: URL of the source\n        \n    Returns:\n        MBFC page URL if found, None otherwise\n    \"\"\"\n    # Convert source name to slug format (lowercase, replace spaces with hyphens)\n    name_slug = source_name.lower().strip()\n    name_slug = re.sub(r'[^a-z0-9\\s-]', '', name_slug)\n    name_slug = re.sub(r'\\s+', '-', name_slug)\n    name_slug = re.sub(r'-+', '-', name_slug)\n    \n    # Extract domain from URL\n    domain = extract_domain(source_url)\n    domain_slug = domain.replace('.', '-') if domain else \"\"\n    \n    # Try different URL patterns\n    patterns_to_try = []\n    if name_slug:\n        patterns_to_try.append(name_slug)\n    if domain_slug and domain_slug != name_slug:\n        patterns_to_try.append(domain_slug)\n    \n    for pattern in patterns_to_try:\n        try:\n            mbfc_url = f\"{MBFC_BASE_URL}{pattern}/\"\n            response = requests.get(mbfc_url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})\n            if response.status_code == 200 and 'Bias Rating:' in response.text:\n                return mbfc_url\n        except Exception:\n            continue\n    \n    return None\n\n\ndef extract_mbfc_data(mbfc_url: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n    \"\"\"\n    Parse MBFC page HTML and extract bias, factual, and credibility ratings.\n    \n    Args:\n        mbfc_url: URL of the MBFC page\n        \n    Returns:\n        Tuple of (bias_rating, factual_rating, credibility_rating)\n    \"\"\"\n    try:\n        response = requests.get(mbfc_url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})\n        if response.status_code != 200:\n            return None, None, None\n        \n        html_content = response.text\n        \n        # Extract bias rating\n        bias_match = re.search(r'Bias Rating:\\s*([A-Z\\s-]+)', html_content, re.IGNORECASE)\n        bias_rating = bias_match.group(1).strip() if bias_match else None\n        \n        # Extract factual reporting\n        factual_match = re.search(r'Factual Reporting:\\s*([A-Z\\s-]+)', html_content, re.IGNORECASE)\n        factual_rating = factual_match.group(1).strip() if factual_match else None\n        \n        # Extract credibility rating\n        credibility_match = re.search(r'Credibility Rating:\\s*([A-Z\\s-]+)', html_content, re.IGNORECASE)\n        if not credibility_match:\n            credibility_match = re.search(r'CREDIBILITY:\\s*([A-Z\\s-]+)', html_content, re.IGNORECASE)\n        credibility_rating = credibility_match.group(1).strip() if credibility_match else None\n        \n        return bias_rating, factual_rating, credibility_rating\n    except Exception as e:\n        return None, None, None\n\n\ndef get_mbfc_ratings(source_name: str, source_url: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n    \"\"\"\n    Combine search and extraction to get MBFC ratings for a source.\n    \n    Args:\n        source_name: Name of the source\n        source_url: URL of the source\n        \n    Returns:\n        Tuple of (bias_rating, factual_rating, credibility_rating)\n    \"\"\"\n    mbfc_url = search_mbfc(source_name, source_url)\n    if mbfc_url:\n        return extract_mbfc_data(mbfc_url)\n    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sheet_row(sheets_service, row_index: int, headers: list, row_data: dict):\n    \"\"\"\n    Update MBFC columns in a specific row of the sheet.\n    \n    Args:\n        sheets_service: Google Sheets service instance\n        row_index: Row number in the sheet (1-indexed)\n        headers: List of column headers\n        row_data: Dictionary with column data including mbfc_bias, mbfc_factual, and mbfc_credibility_rating\n    \"\"\"\n    # Find column indices\n    try:\n        bias_col_idx = headers.index('mbfc_bias')\n        factual_col_idx = headers.index('mbfc_factual')\n        credibility_col_idx = headers.index('mbfc_credibility_rating')\n    except ValueError as e:\n        print(f\"\u274c Required MBFC columns not found in sheet\")\n        print(f\"Available columns: {headers}\")\n        return\n    \n    # Convert column index to letter (0->A, 1->B, etc.)\n    def col_to_letter(col_idx):\n        result = \"\"\n        while col_idx >= 0:\n            result = chr(65 + (col_idx % 26)) + result\n            col_idx = col_idx // 26 - 1\n        return result\n    \n    bias_col = col_to_letter(bias_col_idx)\n    factual_col = col_to_letter(factual_col_idx)\n    credibility_col = col_to_letter(credibility_col_idx)\n    \n    # Update bias rating\n    if row_data.get('mbfc_bias'):\n        range_name = f\"main!{bias_col}{row_index}\"\n        body = {'values': [[row_data['mbfc_bias']]]}\n        sheets_service.spreadsheets().values().update(\n            spreadsheetId=SPREADSHEET_ID,\n            range=range_name,\n            valueInputOption='RAW',\n            body=body\n        ).execute()\n    \n    # Update factual rating\n    if row_data.get('mbfc_factual'):\n        range_name = f\"main!{factual_col}{row_index}\"\n        body = {'values': [[row_data['mbfc_factual']]]}\n        sheets_service.spreadsheets().values().update(\n            spreadsheetId=SPREADSHEET_ID,\n            range=range_name,\n            valueInputOption='RAW',\n            body=body\n        ).execute()\n    \n    # Update credibility rating\n    if row_data.get('mbfc_credibility_rating'):\n        range_name = f\"main!{credibility_col}{row_index}\"\n        body = {'values': [[row_data['mbfc_credibility_rating']]]}\n        sheets_service.spreadsheets().values().update(\n            spreadsheetId=SPREADSHEET_ID,\n            range=range_name,\n            valueInputOption='RAW',\n            body=body\n        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mbfc_enrichment():\n    \"\"\"\n    Main workflow function that processes all sources and enriches them with MBFC data.\n    \"\"\"\n    try:\n        # Load sheet data\n        sheets_service, headers, data_rows = load_sheet_data()\n        \n        # Verify required columns exist\n        if 'mbfc_bias' not in headers or 'mbfc_factual' not in headers or 'mbfc_credibility_rating' not in headers:\n            print(\"\u274c Required columns 'mbfc_bias', 'mbfc_factual', and 'mbfc_credibility_rating' not found\")\n            print(f\"Available columns: {headers}\")\n            print(\"\\nPlease add these columns to your sheet and try again.\")\n            return\n        \n        # Count existing vs needed enrichment\n        already_filled = sum(\n            1 for row in data_rows \n            if row.get('mbfc_bias', '').strip() \n            or row.get('mbfc_factual', '').strip()\n            or row.get('mbfc_credibility_rating', '').strip()\n        )\n        needs_enrichment = len(data_rows) - already_filled\n        \n        print(f\"\ud83d\udcca Status: {already_filled} already have MBFC data, {needs_enrichment} need enrichment\")\n        print(f\"\ud83d\ude80 Starting MBFC enrichment...\\n\")\n        \n        # Process each row\n        start_time = time.time()\n        updated_count = 0\n        skipped_count = 0\n        not_found_count = 0\n        \n        for idx, row in enumerate(data_rows):\n            name = row.get('name', '').strip()\n            url = row.get('url', '').strip()\n            existing_bias = row.get('mbfc_bias', '').strip()\n            existing_factual = row.get('mbfc_factual', '').strip()\n            existing_credibility = row.get('mbfc_credibility_rating', '').strip()\n            row_index = row.get('_row_index')\n            \n            # Skip rows with missing data\n            if not name or not url:\n                print(f\"[{idx + 1}/{len(data_rows)}] \u23ed\ufe0f  Skipping row {row_index}: missing name or URL\")\n                continue\n            \n            # Skip rows that already have all three MBFC fields\n            if existing_bias and existing_factual and existing_credibility:\n                print(f\"[{idx + 1}/{len(data_rows)}] \u23ed\ufe0f  Skipping '{name}': already has MBFC data\")\n                skipped_count += 1\n                continue\n            \n            print(f\"[{idx + 1}/{len(data_rows)}] \ud83d\udd0d Processing: {name}\")\n            print(f\"  URL: {url}\")\n            \n            # Fetch MBFC ratings\n            bias, factual, credibility = get_mbfc_ratings(name, url)\n            \n            if bias or factual or credibility:\n                # Update row data with findings\n                row['mbfc_bias'] = bias or ''\n                row['mbfc_factual'] = factual or ''\n                row['mbfc_credibility_rating'] = credibility or ''\n                \n                try:\n                    update_sheet_row(sheets_service, row_index, headers, row)\n                    updated_count += 1\n                    print(f\"  \ud83d\udcca Bias: {bias or 'N/A'}\")\n                    print(f\"  \ud83d\udcca Factual: {factual or 'N/A'}\")\n                    print(f\"  \ud83d\udcca Credibility: {credibility or 'N/A'}\")\n                    print(f\"  \u2705 Updated sheet\\n\")\n                except Exception as e:\n                    print(f\"  \u274c Error updating sheet: {str(e)}\\n\")\n            else:\n                not_found_count += 1\n                print(f\"  \u274c Not found on MBFC\\n\")\n            \n            # Apply rate limiting\n            time.sleep(DELAY_BETWEEN_REQUESTS)\n        \n        # Print summary\n        elapsed = time.time() - start_time\n        print(f\"\\n{'='*60}\")\n        print(f\"\ud83d\udcca Summary\")\n        print(f\"{'='*60}\")\n        print(f\"\u2705 Sources updated: {updated_count}\")\n        print(f\"\u23ed\ufe0f  Sources skipped (already had data): {skipped_count}\")\n        print(f\"\u274c Sources not found on MBFC: {not_found_count}\")\n        print(f\"\u23f1\ufe0f  Total time elapsed: {elapsed/60:.1f} minutes\")\n        print(f\"{'='*60}\\n\")\n        \n    except Exception as e:\n        print(f\"\u274c Error: {str(e)}\")\n        import traceback\n        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the MBFC enrichment process\n",
    "process_mbfc_enrichment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}